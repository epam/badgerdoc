# !!!! Important !!!!
# This .env file is for running local installation only

# General configuration

LOG_LEVEL=DEBUG

# PostgreSQL dev configuration

POSTGRES_HOST=badgerdoc-postgresql
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=badgerdoc

# S3 configuration
# You should repeat aws creds in both of sections
# because minio lib doesn't use env vars

S3_PROVIDER=minio

# Boto configuration

AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_DEFAULT_REGION=

# Minio dev configuration

S3_SECURE=false
AWS_REGION=

# TODO: We need to unify this configuration, boto3 requires with http, Minio without
# TODO: DEPRECATED S3_ENDPOINT_URL
S3_ENDPOINT_URL=http://badgerdoc-minio:9000
S3_ENDPOINT=badgerdoc-minio:9000
S3_ACCESS_KEY=minioadmin
S3_SECRET_KEY=minioadmin
S3_PREFIX=

MINIO_DEFAULT_BUCKETS=local

# KeyCloak dev configuration
KEYCLOAK_HOST=http://badgerdoc-keycloak:8080

KEYCLOAK_SYSTEM_USER_CLIENT=badgerdoc-internal
KEYCLOAK_SYSTEM_USER_SECRET=

KEYCLOAK_USER=admin
KEYCLOAK_PASSWORD=admin


# Gottenberg dev configuration
GOTENBERG_HOST=gotenberg

# Services

ASSETS_SERVICE_SCHEME=http
ASSETS_SERVICE_HOST=badgerdoc-assets
ASSETS_SERVICE_PORT=8080

ANNOTATION_SERVICE_SCHEME=http
ANNOTATION_SERVICE_HOST=badgerdoc-annotation
ANNOTATION_SERVICE_PORT=8080

JOBS_SERVICE_SCHEME=http
JOBS_SERVICE_HOST=badgerdoc-jobs
JOBS_SERVICE_PORT=8080
JOBS_RUN_PIPELINES_WITH_SIGNED_URL=False
# pre signed urls expire in 48 hours
S3_PRE_SIGNED_EXPIRES_HOURS=48

TAXONOMY_SERVICE_SCHEME=http
TAXONOMY_SERVICE_HOST=badgerdoc-taxonomy
TAXONOMY_SERVICE_PORT=8080

PROCESSING_SERVICE_SCHEME=http
PROCESSING_SERVICE_HOST=badgerdoc-processing
PROCESSING_SERVICE_PORT=8080

CONVERT_SERVICE_SCHEME=http
CONVERT_SERVICE_HOST=badgerdoc-convert
CONVERT_SERVICE_PORT=8080
CONVERT_SERVICE_PDF_ENDPOINT=/pdf/import
CONVERT_SERVICE_TXT_ENDPOINT=/txt/import

USERS_SERVICE_SCHEME=http
USERS_SERVICE_HOST=badgerdoc-users
USERS_SERVICE_PORT=8080

# Web configuration

WEB_CORS=*
KAFKA_BOOTSTRAP_SERVER=badgerdoc-kafka:9092 # TODO: remove port
KAFKA_SEARCH_TOPIC=search
AGREEMENT_SCORE_SERVICE_HOST=localhost:5000 # TODO: remove port
MAX_REQ_SIZE=100M

# Airflow configuration

AIRFLOW_ENABLED=True
AIRFLOW_USERNAME=airflow
AIRFLOW_PASSWORD=airflow
AIRFLOW_SERVICE_SCHEME=http
AIRFLOW_SERVICE_HOST=airflow-webserver
AIRFLOW_SERVICE_PORT=8080
AIRFLOW_SERVICE_PATH_PREFIX=/api/v1


# Databricks configuration

DATABRICKS_ENABLED=False
DATABRICKS_KEY=
DATABRICKS_SERVICE_SCHEME=https
DATABRICKS_SERVICE_HOST=
DATABRICKS_SERVICE_PORT=
